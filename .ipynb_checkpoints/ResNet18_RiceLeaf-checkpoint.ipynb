{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66bc29ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:32.819626Z",
     "start_time": "2021-09-26T15:02:32.813625Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder  \n",
    "from torchvision import models\n",
    "from torch import optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2308ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:33.193676Z",
     "start_time": "2021-09-26T15:02:33.182674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "1191\n",
      "452\n",
      "623\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../input/RiceLeafs\"\n",
    "train_dir = data_dir + \"/train\"\n",
    "valid_dir = data_dir + \"/valid\"\n",
    "diseases = os.listdir(train_dir)\n",
    "brownspot = os.listdir(train_dir + \"/BrownSpot\")\n",
    "healthy = os.listdir(train_dir + \"/Healthy\")\n",
    "hispa = os.listdir(train_dir + \"/Hispa\")\n",
    "leafblast = os.listdir(train_dir + \"/LeafBlast\")\n",
    "print(len(brownspot))\n",
    "print(len(healthy))\n",
    "print(len(hispa))\n",
    "print(len(leafblast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa373fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:33.557787Z",
     "start_time": "2021-09-26T15:02:33.545784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "297\n",
      "113\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "brownspot = os.listdir(valid_dir + \"/BrownSpot\")\n",
    "healthy = os.listdir(valid_dir + \"/Healthy\")\n",
    "hispa = os.listdir(valid_dir + \"/Hispa\")\n",
    "leafblast = os.listdir(valid_dir + \"/LeafBlast\")\n",
    "print(len(brownspot))\n",
    "print(len(healthy))\n",
    "print(len(hispa))\n",
    "print(len(leafblast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b15913e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:33.889883Z",
     "start_time": "2021-09-26T15:02:33.877880Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    # 随机裁剪图像，所得图像为原始面积的0.08到1之间，高宽比在3/4和4/3之间。 \n",
    "    # 然后，缩放图像以创建224 x 224的新图像\n",
    "    transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n",
    "                                             ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # 随机更改亮度，对比度和饱和度\n",
    "    transforms.ColorJitter(brightness=0.4,\n",
    "                                       contrast=0.4,\n",
    "                                       saturation=0.4),\n",
    "    # 添加随机噪声\n",
    "    transforms.ToTensor(),\n",
    "    # 标准化图像的每个通道\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b558bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:34.296623Z",
     "start_time": "2021-09-26T15:02:34.282619Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    # 从图像中心裁切224x224大小的图片\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "249d2c10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:34.723034Z",
     "start_time": "2021-09-26T15:02:34.683007Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "valid_batch_size = 8\n",
    "train = ImageFolder(train_dir, transform=transform_train)\n",
    "valid = ImageFolder(valid_dir, transform=transform_test) \n",
    "train_dl = DataLoader(train, train_batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(valid, valid_batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572d91e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:35.087009Z",
     "start_time": "2021-09-26T15:02:35.073006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325387a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:36.188934Z",
     "start_time": "2021-09-26T15:02:35.454384Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae68014c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:36.204937Z",
     "start_time": "2021-09-26T15:02:36.190934Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_inputs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.BatchNorm1d(num_features=256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 4),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b82f6ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:36.220941Z",
     "start_time": "2021-09-26T15:02:36.205938Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# set optimizer, only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, learning_rate, epochs=epochs, steps_per_epoch=len(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d7b0add",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:02:38.719853Z",
     "start_time": "2021-09-26T15:02:37.320006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=4, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29696bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:12:36.801414Z",
     "start_time": "2021-09-26T15:02:38.720854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Learning Rate0.0000040000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yueqiao\\anaconda3\\envs\\ttorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [10/84], Accuracy: 12.5%, Loss: 1.5934\n",
      "Epoch [1/4], Step [20/84], Accuracy: 34.375%, Loss: 1.4365\n",
      "Epoch [1/4], Step [30/84], Accuracy: 31.25%, Loss: 1.3175\n",
      "Epoch [1/4], Step [40/84], Accuracy: 31.25%, Loss: 1.4525\n",
      "Epoch [1/4], Step [50/84], Accuracy: 40.625%, Loss: 1.2665\n",
      "Epoch [1/4], Step [60/84], Accuracy: 65.625%, Loss: 1.0827\n",
      "Epoch [1/4], Step [70/84], Accuracy: 53.125%, Loss: 1.0351\n",
      "Epoch [1/4], Step [80/84], Accuracy: 75.0%, Loss: 0.6876\n",
      "Epoch [2/4], Learning Rate0.0000941844\n",
      "Epoch [2/4], Step [10/84], Accuracy: 65.625%, Loss: 0.9712\n",
      "Epoch [2/4], Step [20/84], Accuracy: 78.125%, Loss: 0.6954\n",
      "Epoch [2/4], Step [30/84], Accuracy: 62.5%, Loss: 0.9283\n",
      "Epoch [2/4], Step [40/84], Accuracy: 68.75%, Loss: 0.7047\n",
      "Epoch [2/4], Step [50/84], Accuracy: 56.25%, Loss: 0.9173\n",
      "Epoch [2/4], Step [60/84], Accuracy: 65.625%, Loss: 0.8898\n",
      "Epoch [2/4], Step [70/84], Accuracy: 84.375%, Loss: 0.6743\n",
      "Epoch [2/4], Step [80/84], Accuracy: 78.125%, Loss: 0.5403\n",
      "Epoch [3/4], Learning Rate0.0000806497\n",
      "Epoch [3/4], Step [10/84], Accuracy: 75.0%, Loss: 0.5338\n",
      "Epoch [3/4], Step [20/84], Accuracy: 65.625%, Loss: 0.9511\n",
      "Epoch [3/4], Step [30/84], Accuracy: 62.5%, Loss: 0.8005\n",
      "Epoch [3/4], Step [40/84], Accuracy: 78.125%, Loss: 0.6754\n",
      "Epoch [3/4], Step [50/84], Accuracy: 81.25%, Loss: 0.5278\n",
      "Epoch [3/4], Step [60/84], Accuracy: 84.375%, Loss: 0.5507\n",
      "Epoch [3/4], Step [70/84], Accuracy: 71.875%, Loss: 0.7447\n",
      "Epoch [3/4], Step [80/84], Accuracy: 78.125%, Loss: 0.5629\n",
      "Epoch [4/4], Learning Rate0.0000277063\n",
      "Epoch [4/4], Step [10/84], Accuracy: 87.5%, Loss: 0.5130\n",
      "Epoch [4/4], Step [20/84], Accuracy: 84.375%, Loss: 0.5877\n",
      "Epoch [4/4], Step [30/84], Accuracy: 71.875%, Loss: 0.7259\n",
      "Epoch [4/4], Step [40/84], Accuracy: 75.0%, Loss: 0.6030\n",
      "Epoch [4/4], Step [50/84], Accuracy: 84.375%, Loss: 0.6578\n",
      "Epoch [4/4], Step [60/84], Accuracy: 84.375%, Loss: 0.6110\n",
      "Epoch [4/4], Step [70/84], Accuracy: 90.625%, Loss: 0.4096\n",
      "Epoch [4/4], Step [80/84], Accuracy: 78.125%, Loss: 0.6675\n",
      "Finished Training of Res-18\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dl)\n",
    "loss = 0.0\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print ('Epoch [{}/{}], Learning Rate{:.10f}'.format(epoch+1, epochs, optimizer.param_groups[0]['lr']))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            acc_train = 100 * correct_train/total_train\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Accuracy: {}%, Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, acc_train, loss.item()))\n",
    "        running_loss = 0.0\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "print('Finished Training of Res-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b62bc0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:13:11.911279Z",
     "start_time": "2021-09-26T15:12:36.802414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.43 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in valid_dl:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model.forward(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5773894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:13:17.167356Z",
     "start_time": "2021-09-26T15:13:11.913279Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_dl)\n",
    "images, labels = dataiter.next()\n",
    "classes = ('BrownSpot', 'Healthy', 'Hispa', 'LeafBlast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1003296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:15:10.119842Z",
     "start_time": "2021-09-26T15:14:35.431992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of BrownSpot : 26 %\n",
      "Accuracy of Healthy : 93 %\n",
      "Accuracy of Hispa :  8 %\n",
      "Accuracy of LeafBlast :  6 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(38))\n",
    "class_total = list(0. for i in range(38))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in valid_dl:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77778f4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:13:51.782187Z",
     "start_time": "2021-09-26T15:13:51.608146Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = './rice-leaf-model-res18-complete.pth'\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69f323bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:13:51.892215Z",
     "start_time": "2021-09-26T15:13:51.783188Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = './rice-leaf-model-res18-complete.pth'\n",
    "model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa3d43ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T15:14:26.556990Z",
     "start_time": "2021-09-26T15:13:51.893216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.78 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in valid_dl:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model.forward(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300cdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
