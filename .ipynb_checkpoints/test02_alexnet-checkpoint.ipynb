{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a142b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:34.585530Z",
     "start_time": "2021-09-21T19:08:32.612095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\yueqiao\\anaconda3\\envs\\ttorch\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary as summary             \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b2dbe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:34.601533Z",
     "start_time": "2021-09-21T19:08:34.586530Z"
    }
   },
   "outputs": [],
   "source": [
    "'''定义参数'''\n",
    "batch_size=128\n",
    "total_epoch=10\n",
    "lr=0.001\n",
    "classes_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68c60cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:36.095873Z",
     "start_time": "2021-09-21T19:08:34.602534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''获取数据集'''\n",
    "train_dataset=torchvision.datasets.CIFAR10(root='../DataSet/',train=True,download=True,transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset=torchvision.datasets.CIFAR10(root='../DataSet/',train=False,transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc2650e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:36.111877Z",
     "start_time": "2021-09-21T19:08:36.097874Z"
    }
   },
   "outputs": [],
   "source": [
    "'''数据装载'''\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ce6b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:36.127881Z",
     "start_time": "2021-09-21T19:08:36.112877Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        \n",
    "        '''第一层卷积层，卷积核为3*3，通道数为96，步距为1，原始图像大小为32*32，有R、G、B三个通道'''\n",
    "        \n",
    "        '''这样经过第一层卷积层之后，得到的feature map的大小为(32-3)/1+1=30,所以feature map的维度为96*30*30'''\n",
    "        \n",
    "        self.conv1=nn.Conv2d(3,96,kernel_size=3,stride=1)\n",
    "        \n",
    "        '''经过一次批归一化，将数据拉回到正态分布'''\n",
    "        \n",
    "        self.bn1=nn.BatchNorm2d(96)\n",
    "        \n",
    "        '''第一层池化层，卷积核为3*3，步距为2，前一层的feature map的大小为30*30，通道数为96个'''\n",
    "        \n",
    "        '''这样经过第一层池化层之后，得到的feature map的大小为(30-3)/2+1=14,所以feature map的维度为96*14*14'''\n",
    "        \n",
    "        self.pool1=nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        '''第二层卷积层，卷积核为3*3，通道数为256，步距为1，前一层的feature map的大小为14*14，通道数为96个'''\n",
    "        \n",
    "        '''这样经过第一层卷积层之后，得到的feature map的大小为(14-3)/1+1=12,所以feature map的维度为256*12*12'''\n",
    "        \n",
    "        self.conv2=nn.Conv2d(96,256,kernel_size=3,stride=1)\n",
    "        \n",
    "        '''经过一次批归一化，将数据拉回到正态分布'''\n",
    "        \n",
    "        self.bn2=nn.BatchNorm2d(256)\n",
    "        \n",
    "        '''第二层池化层，卷积核为3*3，步距为2，前一层的feature map的大小为12*12，通道数为256个'''\n",
    "        \n",
    "        '''这样经过第二层池化层之后，得到的feature map的大小为(12-3)/2+1=5,所以feature map的维度为256*5*5'''\n",
    "        \n",
    "        self.pool2=nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        '''第三层卷积层，卷积核为3*3，通道数为384，步距为1，前一层的feature map的大小为5*5，通道数为256个'''\n",
    "        \n",
    "        '''这样经过第一层卷积层之后，得到的feature map的大小为(5-3+2*1)/1+1=5,所以feature map的维度为384*5*5'''\n",
    "        \n",
    "        self.conv3=nn.Conv2d(256,384,kernel_size=3,padding=1,stride=1)\n",
    "        \n",
    "        '''第四层卷积层，卷积核为3*3，通道数为384，步距为1，前一层的feature map的大小为5*5，通道数为384个'''\n",
    "        \n",
    "        '''这样经过第一层卷积层之后，得到的feature map的大小为(5-3+2*1)/1+1=5,所以feature map的维度为384*5*5'''\n",
    "        \n",
    "        self.conv4=nn.Conv2d(384,384,kernel_size=3,padding=1,stride=1)\n",
    "        \n",
    "        '''第五层卷积层，卷积核为3*3，通道数为384，步距为1，前一层的feature map的大小为5*5，通道数为384个'''\n",
    "        \n",
    "        '''这样经过第一层卷积层之后，得到的feature map的大小为(5-3+2*1)/1+1=5,所以feature map的维度为256*5*5'''\n",
    "        \n",
    "        self.conv5=nn.Conv2d(384,256,kernel_size=3,padding=1,stride=1)\n",
    "        \n",
    "        '''第三层池化层，卷积核为3*3，步距为2，前一层的feature map的大小为5*5，通道数为256个'''\n",
    "        \n",
    "        '''这样经过第三层池化层之后，得到的feature map的大小为(5-3)/2+1=2,所以feature map的维度为256*2*2'''\n",
    "        \n",
    "        self.pool3=nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        '''经过第一层全连接层'''\n",
    "        \n",
    "        self.linear1=nn.Linear(1024,2048)\n",
    "        \n",
    "        '''经过第一次DropOut层'''\n",
    "        \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "        \n",
    "        '''经过第二层全连接层'''\n",
    "        \n",
    "        self.linear2=nn.Linear(2048,2048)\n",
    "        \n",
    "        '''经过第二层DropOut层'''\n",
    "        \n",
    "        self.dropout2=nn.Dropout(0.5)\n",
    "        \n",
    "        '''经过第三层全连接层，得到输出结果'''\n",
    "        \n",
    "        self.linear3=nn.Linear(2048,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=F.relu(out)\n",
    "        out=self.pool1(out)\n",
    "        \n",
    "        \n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out=F.relu(out)\n",
    "        out=self.pool2(out)\n",
    "        \n",
    "        out=F.relu(self.conv3(out))\n",
    "        \n",
    "        out=F.relu(self.conv4(out))\n",
    "        \n",
    "        out=F.relu(self.conv5(out))\n",
    "        \n",
    "        out=self.pool3(out)\n",
    "        \n",
    "        out=out.reshape(-1,256*2*2)\n",
    "        \n",
    "        out=F.relu(self.linear1(out))\n",
    "        \n",
    "        out=self.dropout1(out)\n",
    "        \n",
    "        out=F.relu(self.linear2(out))\n",
    "        \n",
    "        out=self.dropout2(out)\n",
    "        \n",
    "        out=self.linear3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd1e27a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:36.143885Z",
     "start_time": "2021-09-21T19:08:36.128881Z"
    }
   },
   "outputs": [],
   "source": [
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8fdeca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:36.159888Z",
     "start_time": "2021-09-21T19:08:36.144885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349aebc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:08:36.175891Z",
     "start_time": "2021-09-21T19:08:36.160889Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader= DeviceDataLoader(train_loader,device)\n",
    "test_loader= DeviceDataLoader(test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0813581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:09:01.341772Z",
     "start_time": "2021-09-21T19:08:59.022253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yueqiao\\anaconda3\\envs\\ttorch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [128, 96, 30, 30]           2,688\n",
      "       BatchNorm2d-2          [128, 96, 30, 30]             192\n",
      "         MaxPool2d-3          [128, 96, 14, 14]               0\n",
      "            Conv2d-4         [128, 256, 12, 12]         221,440\n",
      "       BatchNorm2d-5         [128, 256, 12, 12]             512\n",
      "         MaxPool2d-6           [128, 256, 5, 5]               0\n",
      "            Conv2d-7           [128, 384, 5, 5]         885,120\n",
      "            Conv2d-8           [128, 384, 5, 5]       1,327,488\n",
      "            Conv2d-9           [128, 256, 5, 5]         884,992\n",
      "        MaxPool2d-10           [128, 256, 2, 2]               0\n",
      "           Linear-11                [128, 2048]       2,099,200\n",
      "          Dropout-12                [128, 2048]               0\n",
      "           Linear-13                [128, 2048]       4,196,352\n",
      "          Dropout-14                [128, 2048]               0\n",
      "           Linear-15                  [128, 10]          20,490\n",
      "================================================================\n",
      "Total params: 9,638,474\n",
      "Trainable params: 9,638,474\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 299.38\n",
      "Params size (MB): 36.77\n",
      "Estimated Total Size (MB): 337.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model=AlexNet().cuda()\n",
    "\n",
    "summary.summary(model, input_size=(3, 32, 32),batch_size=128,device=\"cuda\")\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0464169f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:09:04.997560Z",
     "start_time": "2021-09-21T19:09:04.981563Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16b54467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:10:31.098370Z",
     "start_time": "2021-09-21T19:09:08.316452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/391], Loss: 1.6349\n",
      "Epoch [1/10], Step [200/391], Loss: 1.5807\n",
      "Epoch [1/10], Step [300/391], Loss: 1.3399\n",
      "Epoch [2/10], Step [100/391], Loss: 1.3617\n",
      "Epoch [2/10], Step [200/391], Loss: 1.1609\n",
      "Epoch [2/10], Step [300/391], Loss: 1.1742\n",
      "Epoch [3/10], Step [100/391], Loss: 0.9579\n",
      "Epoch [3/10], Step [200/391], Loss: 0.9080\n",
      "Epoch [3/10], Step [300/391], Loss: 1.0999\n",
      "Epoch [4/10], Step [100/391], Loss: 0.9459\n",
      "Epoch [4/10], Step [200/391], Loss: 0.9255\n",
      "Epoch [4/10], Step [300/391], Loss: 1.0541\n",
      "Epoch [5/10], Step [100/391], Loss: 0.8641\n",
      "Epoch [5/10], Step [200/391], Loss: 0.6653\n",
      "Epoch [5/10], Step [300/391], Loss: 0.5922\n",
      "Epoch [6/10], Step [100/391], Loss: 0.7022\n",
      "Epoch [6/10], Step [200/391], Loss: 0.7422\n",
      "Epoch [6/10], Step [300/391], Loss: 0.8447\n",
      "Epoch [7/10], Step [100/391], Loss: 0.7078\n",
      "Epoch [7/10], Step [200/391], Loss: 0.9009\n",
      "Epoch [7/10], Step [300/391], Loss: 0.9358\n",
      "Epoch [8/10], Step [100/391], Loss: 0.6653\n",
      "Epoch [8/10], Step [200/391], Loss: 0.7233\n",
      "Epoch [8/10], Step [300/391], Loss: 0.5550\n",
      "Epoch [9/10], Step [100/391], Loss: 0.5119\n",
      "Epoch [9/10], Step [200/391], Loss: 0.7819\n",
      "Epoch [9/10], Step [300/391], Loss: 0.6768\n",
      "Epoch [10/10], Step [100/391], Loss: 0.5873\n",
      "Epoch [10/10], Step [200/391], Loss: 0.7336\n",
      "Epoch [10/10], Step [300/391], Loss: 0.5392\n"
     ]
    }
   ],
   "source": [
    "'''开始训练'''\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "#         images=Variable(images)\n",
    "#         labels=Variable(labels)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f132cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T19:20:28.739415Z",
     "start_time": "2021-09-21T19:20:28.736423Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f749af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
