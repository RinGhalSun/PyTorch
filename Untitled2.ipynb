{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cdeb258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:26:31.297488Z",
     "start_time": "2021-09-27T01:26:29.971189Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder  \n",
    "from torchvision import models\n",
    "from torch import optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c784a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:26:35.126354Z",
     "start_time": "2021-09-27T01:26:35.115352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Potato___Late_blight', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___healthy', 'Strawberry___Leaf_scorch', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../input/New Plant Diseases Dataset\"\n",
    "train_dir = data_dir + \"/train\"\n",
    "valid_dir = data_dir + \"/valid\"\n",
    "diseases = os.listdir(train_dir)\n",
    "print(diseases)\n",
    "print(len(diseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1907886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:26:40.636601Z",
     "start_time": "2021-09-27T01:26:40.620597Z"
    }
   },
   "outputs": [],
   "source": [
    "transform= transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c15173c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:26:48.101289Z",
     "start_time": "2021-09-27T01:26:47.391129Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train = ImageFolder(train_dir, transform=transform)\n",
    "valid = ImageFolder(valid_dir, transform=transform) \n",
    "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d97d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:26:56.316147Z",
     "start_time": "2021-09-27T01:26:53.626539Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad967cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:26:59.065769Z",
     "start_time": "2021-09-27T01:26:58.516645Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(25088, 4096),\n",
    "                          nn.Dropout(p = 0.5),\n",
    "                          nn.BatchNorm1d(num_features=4096),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(4096, 1024),\n",
    "                          nn.Dropout(p = 0.5),\n",
    "                          nn.BatchNorm1d(num_features=1024),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(1024, 38))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95938d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:27:03.096681Z",
     "start_time": "2021-09-27T01:27:03.091680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78d6d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:27:15.549498Z",
     "start_time": "2021-09-27T01:27:15.532494Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abde199f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T01:27:21.306800Z",
     "start_time": "2021-09-27T01:27:19.438377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=1024, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_dl)\n",
    "num_epoch = 20\n",
    "List_acc_valid=[]\n",
    "List_acc_train=[]  \n",
    "List_loss_valid=[]\n",
    "List_loss_train=[]\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    AlexNet.train()\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = AlexNet(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 275 == 274:    # print every 1000 mini-batches\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            acc_train = 100 * correct_train/total_train\n",
    "            running_loss = 0.0\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Accuracy: {}%, Loss: {:.4f}'.format(epoch+1, num_epoch, i+1, total_step, acc_train, loss.item()))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valid_dl:\n",
    "            images_valid, labels_valid = data[0].to(device), data[1].to(device)\n",
    "            outputs_valid = AlexNet(images_valid)\n",
    "            loss_valid = criterion(outputs_valid, labels_valid)\n",
    "            _, predicted = torch.max(outputs_valid.data, 1)\n",
    "            total += labels_valid.size(0)\n",
    "            correct += (predicted == labels_valid).sum().item()\n",
    "            acc_valid = 100 * correct / total\n",
    "        print('Accuracy: %.2f %%' % (100 * correct / total))\n",
    "        print(loss_valid.item())\n",
    "        \n",
    "        List_acc_valid.append(acc_valid)\n",
    "        List_acc_train.append(acc_train)\n",
    "        List_loss_valid.append(loss_valid.item())\n",
    "        List_loss_train.append(loss.item()) \n",
    "print('Finished Training of AlexNet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
